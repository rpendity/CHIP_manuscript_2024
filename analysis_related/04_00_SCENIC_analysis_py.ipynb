{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seacells-pyscenic analysis\n",
    "\n",
    "caution : this analysis needs > 200GB Memory in total. if needed, please split script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from SEACells.core import SEACells, summarize_by_SEACell, summarize_by_soft_SEACell\n",
    "from SEACells.plot import plot_initialization, plot_2D, plot_SEACell_sizes\n",
    "import loompy as lp\n",
    "import scanpy.external as sce\n",
    "# Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a working directory\n",
    "wdir = \"202111-CHIP/scRNA_gca_scenic/3_SEACells/\"\n",
    "os.chdir( wdir )\n",
    "\n",
    "chr_loom_path = \"./CHIP_unfiltered_SCT_normalized.loom\"\n",
    "chr_md_path = \"./seurat_md.txt.gz\"\n",
    "chr_anndata_path = \"./anndata.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_loom(chr_loom_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_R = pd.read_csv(chr_md_path, sep = \"\\t\")\n",
    "df_from_R = df_from_R[[\"cell\",\"anno_l1\" ,\"sample\", \"batch\", \"response\", \"time\", \"CHIP_Binary\", \"CHIP_Severity\", \"CHIP_MaxAF\"]]\n",
    "df_from_R.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obs = adata.obs[[\"nGene\", \"nUMI\", \"seuratCluster\"]]\n",
    "df_obs = df_obs.reset_index()\n",
    "df_obs = pd.merge(df_obs, df_from_R, left_on= \"CellID\", right_on=\"cell\")\n",
    "df_obs = df_obs.set_index(\"CellID\")\n",
    "df_obs\n",
    "adata.obs = df_obs\n",
    "adata.obs[\"group\"] = adata.obs[[\"sample\", \"time\"]].apply(\"-\".join, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.normalize_per_cell(adata)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, n_comps = 50, use_highly_variable= True)\n",
    "sc.pl.pca_variance_ratio(adata, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sce.pp.harmony_integrate(adata, 'group', max_iter_harmony = 10)\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=30, use_rep = \"X_pca_harmony\")\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata, resolution=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata, color=['leiden'],\n",
    "show=False,\n",
    "    legend_fontsize=6, frameon=True, title='Leiden')\n",
    "sc.pl.umap(adata, color=['anno_l1'],\n",
    "show=False,\n",
    "    legend_fontsize=6, frameon=True, title='Leiden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata.write(chr_anndata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_R[\"group\"] = df_from_R[[\"sample\", \"time\"]].apply(\"-\".join, axis = 1)\n",
    "list_group = df_from_R[\"group\"].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each_name in list_group:\n",
    "    each_adata = adata[adata.obs[\"group\"].isin([each_name])]\n",
    "    # automatically find number of SEACells \n",
    "    n_cells = each_adata.obs.shape[0]\n",
    "    n_SEAcells = int(np.floor(n_cells/75))\n",
    "    build_kernel_on = 'X_pca_harmony' # to using adjusted PCA\n",
    "    ## Additional parameters\n",
    "    n_waypoint_eigs = 10 # Number of eigenvalues to consider when initializing metacells\n",
    "    print(\"number of SEACells = \", n_SEAcells)\n",
    "    raw_ad = sc.AnnData(each_adata.X)\n",
    "    raw_ad.obs_names, raw_ad.var_names = each_adata.obs_names, each_adata.var_names\n",
    "    each_adata.raw = raw_ad\n",
    "    \n",
    "    model =  SEACells(each_adata, \n",
    "                  build_kernel_on=build_kernel_on, \n",
    "                  n_SEACells=n_SEAcells, \n",
    "                  n_waypoint_eigs=n_waypoint_eigs,\n",
    "                  convergence_epsilon = 1e-5)\n",
    "    model.construct_kernel_matrix()\n",
    "    M = model.kernel_matrix\n",
    "    sns.clustermap(M.toarray()[:500,:500])\n",
    "    # Initialize archetypes\n",
    "    model.initialize_archetypes()\n",
    "    # Plot the initilization to ensure they are spread across phenotypic space\n",
    "    plot_initialization(each_adata, model)\n",
    "    # Check for convergence \n",
    "    model.fit(min_iter=10, max_iter=100)\n",
    "    model.plot_convergence()\n",
    "    plt.figure(figsize=(3,2))\n",
    "    sns.distplot((model.A_.T > 0.1).sum(axis=1), kde=False)\n",
    "    plt.title(f'Non-trivial (> 0.1) assignments per cell')\n",
    "    plt.xlabel('# Non-trivial SEACell Assignments')\n",
    "    plt.ylabel('# Cells')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(3,2))\n",
    "    b = np.partition(model.A_.T, -5)    \n",
    "    sns.heatmap(np.sort(b[:,-5:])[:, ::-1], cmap='viridis', vmin=0)\n",
    "    plt.title('Strength of top 5 strongest assignments')\n",
    "    plt.xlabel('$n^{th}$ strongest assignment')\n",
    "    plt.show()\n",
    "    \n",
    "    SEACell_adata = summarize_by_SEACell(each_adata, SEACells_label='SEACell', summarize_layer='raw')\n",
    "    SEACell_adata\n",
    "    SEACell_soft_adata = summarize_by_soft_SEACell(each_adata, model.A_, celltype_label='anno_l1',summarize_layer='raw', minimum_weight=0.05)\n",
    "    SEACell_soft_adata.obs.head\n",
    "    plot_2D(each_adata, key='X_umap', colour_metacells=True)\n",
    "    each_adata.obs['cell'] = each_adata.obs['group'].astype(str) +\"-\"+ each_adata.obs[\"cell\"]\n",
    "    each_adata.obs.head\n",
    "    plot_SEACell_sizes(each_adata, bins=5)\n",
    "    each_adata.write(\"./each_anndata/\"+each_name+\".h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [i+\".h5ad\" for i in list_group]\n",
    "list_h5ad = [sc.read_h5ad(\"/mnt/workspace/202111-CHIP/scRNA_gca_scenic/3_SEACells/each_anndata/\"+each_fname) for each_fname in fnames]\n",
    "adata = list_h5ad[1].concatenate(list_h5ad[2:])\n",
    "adata.write(\"./anndata.seacells.h5ad\")\n",
    "adata.obs[\"Cell\"] = adata.obs[[\"sample\", \"time\", \"SEACell\"]].apply(\"-\".join, axis = 1)\n",
    "adata.obs = adata.obs.drop(\"cell\", axis = 1)\n",
    "adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEACell_adata = summarize_by_SEACell(adata, SEACells_label='Cell', summarize_layer='raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meta =( adata.\n",
    "          obs[[\"sample\", \"batch\", \"response\", \"time\", \"CHIP_Binary\", \"CHIP_Severity\", \"group\",\"Cell\"]].\n",
    "          drop_duplicates().\n",
    "          set_index(\"Cell\")\n",
    "        )\n",
    "\n",
    "SEACell_adata.obs = pd.merge(SEACell_adata.obs, df_meta, left_index = True, right_index = True, how = \"inner\")\n",
    "SEACell_adata.write(\"./anndata.seacells_summarized.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEACell_adata = sc.read_h5ad(\"./anndata.seacells_summarized.h5ad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic row and column attributes for the loom file:\n",
    "row_attrs = {\n",
    "    \"Gene\": np.array(SEACell_adata.var_names) ,\n",
    "}\n",
    "col_attrs = {\n",
    "    \"CellID\": np.array(SEACell_adata.obs_names) ,\n",
    "    \"nGene\": np.array( np.sum(SEACell_adata.X.transpose()>0 , axis=0)).flatten() ,\n",
    "    \"nUMI\": np.array( np.sum(SEACell_adata.X.transpose() , axis=0)).flatten() ,\n",
    "    \"Louvain_clusters_Scanpy\": np.array( SEACell_adata.obs['leiden'].values ),\n",
    "    \"group\": np.array(SEACell_adata.obs['group'].values),\n",
    "    \"time\": np.array(SEACell_adata.obs['time'].values),\n",
    "    \"sample\": np.array(SEACell_adata.obs['sample'].values),\n",
    "}\n",
    "lp.create(\"SEACells.loom\", SEACell_adata.X.transpose(), row_attrs, col_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRN construction based on SEACells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables for file paths to read from and write to:\n",
    "\n",
    "# set a working directory\n",
    "wdir = \"/mnt/workspace/202111-CHIP/scRNA_gca_scenic/3_SEACells/\"\n",
    "os.chdir( wdir )\n",
    "\n",
    "# path to unfiltered loom file (this will be created in the optional steps below)\n",
    "f_loom_path_unfilt = \"SEACells.loom\" \n",
    "\n",
    "# # path to loom file with basic filtering applied (this will be created in the \"initial filtering\" step below). Optional.\n",
    "f_loom_path_scenic = \"SEACells.filtered.loom\"\n",
    "\n",
    "# path to anndata object, which will be updated to store Scanpy results as they are generated below\n",
    "f_anndata_path = \"anndata_scenic.h5ad\"\n",
    "\n",
    "# path to pyscenic output\n",
    "f_pyscenic_output = \"pyscenic_output.loom\"\n",
    "\n",
    "# loom output, generated from a combination of Scanpy and pySCENIC results:\n",
    "#f_final_loom = 'CHIP_sample10p_scenic_integrated-output.loom'\n",
    "f_final_loom = 'CHIP-scenic-integrated-output.loom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_loom(f_loom_path_unfilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCells=adata.X.shape[0]\n",
    "\n",
    "# pySCENIC thresholds\n",
    "minCountsPerGene=3*.01*nCells # 3 counts in 1% of cells\n",
    "print(\"minCountsPerGene: \", minCountsPerGene)\n",
    "\n",
    "minSamples=.01*nCells # 1% of cells\n",
    "print(\"minSamples: \", minSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simply compute the number of genes per cell (computers 'n_genes' column)\n",
    "sc.pp.filter_cells(adata, min_genes=0)\n",
    "# mito and genes/counts cuts\n",
    "mito_genes = adata.var_names.str.startswith('MT-')\n",
    "# for each cell compute fraction of counts in mito genes vs. all genes\n",
    "adata.obs['percent_mito'] = np.sum(\n",
    "    adata[:, mito_genes].X, axis=1).A1 / np.sum(adata.X, axis=1).A1\n",
    "# add the total counts per cell as observations-annotation to adata\n",
    "adata.obs['n_counts'] = adata.X.sum(axis=1).A1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), dpi=150, sharey=True)\n",
    "\n",
    "x = adata.obs['n_genes']\n",
    "x_lowerbound = 1500\n",
    "x_upperbound = 2000\n",
    "nbins=100\n",
    "\n",
    "sns.histplot(x, ax=ax1, bins=nbins, kde = True)\n",
    "sns.histplot(x, ax=ax2, bins=nbins, kde = True)\n",
    "sns.histplot(x, ax=ax3, bins=nbins, kde = True)\n",
    "\n",
    "ax2.set_xlim(0,x_lowerbound)\n",
    "ax3.set_xlim(x_upperbound, adata.obs['n_genes'].max() )\n",
    "\n",
    "for ax in (ax1,ax2,ax3): \n",
    "  ax.set_xlabel('')\n",
    "\n",
    "ax1.title.set_text('n_genes')\n",
    "ax2.title.set_text('n_genes, lower bound')\n",
    "ax3.title.set_text('n_genes, upper bound')\n",
    "\n",
    "fig.text(-0.01, 0.5, 'Frequency', ha='center', va='center', rotation='vertical', size='x-large')\n",
    "fig.text(0.5, 0.0, 'Genes expressed per cell', ha='center', va='center', size='x-large')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), dpi=150, sharey=True)\n",
    "\n",
    "x = adata.obs['percent_mito']\n",
    "x_lowerbound = [0.0, 0.07 ]\n",
    "x_upperbound = [ 0.10, 0.3 ]\n",
    "nbins=100\n",
    "\n",
    "sns.histplot(x, ax=ax1, kde=True, bins=nbins)\n",
    "sns.histplot(x, ax=ax2, kde=True, bins=int(nbins/(x_lowerbound[1]-x_lowerbound[0])) )\n",
    "sns.histplot(x, ax=ax3, kde=True, bins=int(nbins/(x_upperbound[1]-x_upperbound[0])) )\n",
    "\n",
    "ax2.set_xlim(x_lowerbound[0], x_lowerbound[1])\n",
    "ax3.set_xlim(x_upperbound[0], x_upperbound[1] )\n",
    "for ax in (ax1,ax2,ax3): \n",
    "  ax.set_xlabel('')\n",
    "\n",
    "ax1.title.set_text('percent_mito')\n",
    "ax2.title.set_text('percent_mito, lower bound')\n",
    "ax3.title.set_text('percent_mito, upper bound')\n",
    "\n",
    "fig.text(-0.01, 0.5, 'Frequency', ha='center', va='center', rotation='vertical', size='x-large')\n",
    "fig.text(0.5, 0.0, 'Mitochondrial read fraction per cell', ha='center', va='center', size='x-large')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 4), dpi=150, sharey=False)\n",
    "\n",
    "sns.histplot( adata.obs['n_genes'], ax=ax1, kde=True, bins=100)\n",
    "sns.histplot( adata.obs['n_counts'], ax=ax2, kde=True, bins=100)\n",
    "sns.histplot( adata.obs['percent_mito'], ax=ax3, kde=True, bins=100)\n",
    "\n",
    "ax1.title.set_text('Number of genes expressed per cell')\n",
    "ax2.title.set_text('Counts per cell')\n",
    "ax3.title.set_text('Mitochondrial read fraction per cell')\n",
    "\n",
    "fig.text(-0.01, 0.5, 'Frequency', ha='center', va='center', rotation='vertical', size='x-large')\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig('filtering_panel_prefilter.pdf', dpi=600, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.scatter(adata, x='n_counts', y='n_genes', color='percent_mito')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not needed : adata = adata[adata.obs['percent_mito'] < 0.15, :]\n",
    "adata.write( f_anndata_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic row and column attributes for the loom file:\n",
    "row_attrs = {\n",
    "    \"Gene\": np.array(adata.var_names) ,\n",
    "}\n",
    "col_attrs = {\n",
    "    \"CellID\": np.array(adata.obs_names) ,\n",
    "    \"nGene\": np.array( np.sum(adata.X.transpose()>0 , axis=0)).flatten() ,\n",
    "    \"nUMI\": np.array( np.sum(adata.X.transpose() , axis=0)).flatten() ,\n",
    "    \"Louvain_clusters_Scanpy\": np.array(adata.obs['Louvain_clusters_Scanpy'].values ),\n",
    "    \"group\": np.array(adata.obs['group'].values),\n",
    "    \"time\": np.array(adata.obs['time'].values),\n",
    "    \"sample\": np.array(adata.obs['sample'].values),\n",
    "}\n",
    "lp.create( f_loom_path_scenic, adata.X.transpose(), row_attrs, col_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a copy of the raw data\n",
    "adata.raw = adata\n",
    "\n",
    "# Total-count normalize (library-size correct) to 10,000 reads/cell\n",
    "sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)\n",
    "\n",
    "# log transform the data.\n",
    "sc.pp.log1p(adata)\n",
    "\n",
    "# identify highly variable genes.\n",
    "sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5)\n",
    "sc.pl.highly_variable_genes(adata)\n",
    "\n",
    "# keep only highly variable genes:\n",
    "adata = adata[:, adata.var['highly_variable']]\n",
    "\n",
    "# regress out total counts per cell and the percentage of mitochondrial genes expressed\n",
    "sc.pp.regress_out(adata, ['n_counts', 'percent_mito'], n_jobs=24)\n",
    "\n",
    "# scale each gene to unit variance, clip values exceeding SD 10.\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "\n",
    "# update the anndata file:\n",
    "adata.write( f_anndata_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata, svd_solver='arpack')\n",
    "sc.pl.pca_variance_ratio(adata, log=True)\n",
    "sce.pp.harmony_integrate(adata, 'group', max_iter_harmony = 20)\n",
    "sc.pp.neighbors(adata, n_neighbors=10, n_pcs=30, use_rep = \"X_pca_harmony\")\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata, resolution= 0.4)\n",
    "adata.write( f_anndata_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create basic row and column attributes for the loom file:\n",
    "row_attrs = {\n",
    "    \"Gene\": np.array(adata.var_names) ,\n",
    "}\n",
    "col_attrs = {\n",
    "    \"CellID\": np.array(adata.obs_names) ,\n",
    "    \"nGene\": np.array( np.sum(adata.X.transpose()>0 , axis=0)).flatten() ,\n",
    "    \"nUMI\": np.array( np.sum(adata.X.transpose() , axis=0)).flatten() ,\n",
    "    \"Louvain_clusters_Scanpy\": np.array(adata.obs['Louvain_clusters_Scanpy'].values ),\n",
    "    \"group\": np.array(adata.obs['group'].values),\n",
    "    \"time\": np.array(adata.obs['time'].values),\n",
    "    \"sample\": np.array(adata.obs['sample'].values),\n",
    "}\n",
    "lp.create( f_loom_path_scenic, adata.X.transpose(), row_attrs, col_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription factors list, provided from scenic\n",
    "f_tfs = \"/mnt/workspace/202111-CHIP/scRNA_gca_scenic/cisTarget_databases/allTFs_hg38.txt\" # human\n",
    "# f_tfs = \"/ddn1/vol1/staging/leuven/stg_00002/lcb/cflerin/resources/allTFs_dmel.txt\" # drosophila\n",
    "# f_tfs = \"/ddn1/vol1/staging/leuven/stg_00002/lcb/cflerin/resources/allTFs_mm.txt\"   # mouse\n",
    "# tf_names = load_tf_names( f_tfs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/envs/scenicplus/bin/pyscenic grn {f_loom_path_scenic} {f_tfs} -o adj.csv --num_workers 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacencies = pd.read_csv(\"adj.csv\", index_col=False, sep=',')\n",
    "adjacencies[adjacencies[\"TF\"].isin([\"NFKB1\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# ranking databases\n",
    "f_db_glob = \"/mnt/workspace/202111-CHIP/scRNA_gca_scenic/cisTarget_databases/*rankings.feather\"\n",
    "f_db_names = ' '.join( glob.glob(f_db_glob) )\n",
    "\n",
    "# motif databases\n",
    "f_motif_path = \"/mnt/workspace/202111-CHIP/scRNA_gca_scenic/cisTarget_databases/motifs-v9-nr.hgnc-m0.001-o0.0.tbl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/envs/scenicplus/bin/pyscenic ctx adj.csv \\\n",
    "    {f_db_names} \\\n",
    "    --annotations_fname {f_motif_path} \\\n",
    "    --expression_mtx_fname {f_loom_path_scenic} \\\n",
    "    --output reg.csv \\\n",
    "    --mask_dropouts \\\n",
    "    --num_workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nGenesDetectedPerCellbefore = np.sum(adata.X>0, axis=1)\n",
    "nGenesDetectedPerCell = pd.Series(nGenesDetectedPerCellbefore)\n",
    "percentiles = nGenesDetectedPerCell.quantile([0.01, 0.05, 0.10, 0.50, 1])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5), dpi=150)\n",
    "sns.distplot(nGenesDetectedPerCell, norm_hist=False, kde=False, bins='fd')\n",
    "for i,x in enumerate(percentiles):\n",
    "    fig.gca().axvline(x=x, ymin=0,ymax=1, color='red')\n",
    "    ax.text(x=x, y=ax.get_ylim()[1], s=f'{int(x)} ({percentiles.index.values[i]*100}%)', color='red', rotation=30, size='x-small',rotation_mode='anchor' )\n",
    "ax.set_xlabel('# of genes')\n",
    "ax.set_ylabel('# of cells')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/conda/envs/scenicplus/bin/pyscenic aucell \\\n",
    "    {f_loom_path_scenic} \\\n",
    "    reg.csv \\\n",
    "    --auc_threshold 0.01 \\\n",
    "    --output {f_pyscenic_output} \\\n",
    "    --num_workers 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import zlib\n",
    "import base64\n",
    "\n",
    "# collect SCENIC AUCell output\n",
    "lf = lp.connect( f_pyscenic_output, mode='r+', validate=False )\n",
    "auc_mtx = pd.DataFrame( lf.ca.RegulonsAUC, index=lf.ca.CellID)\n",
    "lf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "# UMAP\n",
    "runUmap = umap.UMAP(n_neighbors=10, min_dist=0.4, metric='correlation').fit_transform\n",
    "dr_umap = runUmap( auc_mtx )\n",
    "pd.DataFrame(dr_umap, columns=['X', 'Y'], index=auc_mtx.index).to_csv( \"scenic_umap.txt\", sep='\\t')\n",
    "# tSNE\n",
    "tsne = TSNE( n_jobs=20 )\n",
    "dr_tsne = tsne.fit_transform( auc_mtx )\n",
    "pd.DataFrame(dr_tsne, columns=['X', 'Y'], index=auc_mtx.index).to_csv( \"scenic_tsne.txt\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenic output\n",
    "lf = lp.connect( f_pyscenic_output, mode='r+', validate=False )\n",
    "meta = json.loads(zlib.decompress(base64.b64decode( lf.attrs.MetaData )))\n",
    "#exprMat = pd.DataFrame( lf[:,:], index=lf.ra.Gene, columns=lf.ca.CellID)\n",
    "auc_mtx = pd.DataFrame( lf.ca.RegulonsAUC, index=lf.ca.CellID)\n",
    "regulons = lf.ra.Regulons\n",
    "dr_umap = pd.read_csv( 'scenic_umap.txt', sep='\\t', header=0, index_col=0 )\n",
    "dr_tsne = pd.read_csv( 'scenic_tsne.txt', sep='\\t', header=0, index_col=0 )\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_mtx.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_mtx.columns = auc_mtx.columns.str.replace('\\(','_(',regex=True)\n",
    "regulons.dtype.names = tuple( [ x.replace(\"(\",\"_(\") for x in regulons.dtype.names ] )\n",
    "# regulon thresholds\n",
    "rt = meta['regulonThresholds']\n",
    "for i,x in enumerate(rt):\n",
    "    tmp = x.get('regulon').replace(\"(\",\"_(\")\n",
    "    x.update( {'regulon': tmp} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsneDF = pd.DataFrame(adata.obsm['X_tsne'], columns=['_X', '_Y'])\n",
    "\n",
    "Embeddings_X = pd.DataFrame( index=lf.ca.CellID )\n",
    "Embeddings_X = pd.concat( [\n",
    "        pd.DataFrame(adata.obsm['X_umap'],index=adata.obs.index)[0] ,\n",
    "        pd.DataFrame(adata.obsm['X_pca'],index=adata.obs.index)[0] ,\n",
    "        dr_tsne['X'] ,\n",
    "        dr_umap['X']\n",
    "    ], sort=False, axis=1, join='outer' )\n",
    "Embeddings_X.columns = ['1','2','3','4']\n",
    "\n",
    "Embeddings_Y = pd.DataFrame( index=lf.ca.CellID )\n",
    "Embeddings_Y = pd.concat( [\n",
    "        pd.DataFrame(adata.obsm['X_umap'],index=adata.obs.index)[1] ,\n",
    "        pd.DataFrame(adata.obsm['X_pca'],index=adata.obs.index)[1] ,\n",
    "        dr_tsne['Y'] ,\n",
    "        dr_umap['Y']\n",
    "    ], sort=False, axis=1, join='outer' )\n",
    "Embeddings_Y.columns = ['1','2','3','4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### metadata\n",
    "metaJson = {}\n",
    "\n",
    "metaJson['embeddings'] = [\n",
    "    {\n",
    "        \"id\": -1,\n",
    "        \"name\": f\"Scanpy t-SNE (highly variable genes)\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": f\"Scanpy UMAP  (highly variable genes)\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"name\": \"Scanpy PC1/PC2\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"name\": \"SCENIC AUC t-SNE\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"name\": \"SCENIC AUC UMAP\"\n",
    "    },\n",
    "]\n",
    "\n",
    "metaJson[\"clusterings\"] = [{\n",
    "            \"id\": 0,\n",
    "            \"group\": \"Scanpy\",\n",
    "            \"name\": \"Scanpy louvain default resolution\",\n",
    "            \"clusters\": [],\n",
    "        }]\n",
    "\n",
    "metaJson[\"metrics\"] = [\n",
    "        {\n",
    "            \"name\": \"nUMI\"\n",
    "        }, {\n",
    "            \"name\": \"nGene\"\n",
    "        }, {\n",
    "            \"name\": \"Percent_mito\"\n",
    "        }\n",
    "]\n",
    "\n",
    "metaJson[\"annotations\"] = [\n",
    "    {\n",
    "        \"name\": \"Louvain_clusters_Scanpy\",\n",
    "        \"values\": list(set( adata.obs['leiden'].astype(str) ))\n",
    "    },\n",
    "    #{\n",
    "    #    \"name\": \"Genotype\",\n",
    "    #    \"values\": list(set(adata.obs['Genotype'].values))\n",
    "    #},\n",
    "    #{\n",
    "    #    \"name\": \"Timepoint\",\n",
    "    #    \"values\": list(set(adata.obs['Timepoint'].values))\n",
    "    #},\n",
    "    #{\n",
    "    #    \"name\": \"Sample\",\n",
    "    #    \"values\": list(set(adata.obs['Sample'].values))\n",
    "    #}\n",
    "]\n",
    "\n",
    "# SCENIC regulon thresholds:\n",
    "metaJson[\"regulonThresholds\"] = rt\n",
    "\n",
    "for i in range(max(set([int(x) for x in adata.obs['leiden']])) + 1):\n",
    "    clustDict = {}\n",
    "    clustDict['id'] = i\n",
    "    clustDict['description'] = f'Unannotated Cluster {i + 1}'\n",
    "    metaJson['clusterings'][0]['clusters'].append(clustDict)\n",
    "    \n",
    "clusterings = pd.DataFrame()\n",
    "clusterings[\"0\"] = adata.obs['leiden'].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfToNamedMatrix(df):\n",
    "    arr_ip = [tuple(i) for i in df.values]\n",
    "    dtyp = np.dtype(list(zip(df.dtypes.index, df.dtypes)))\n",
    "    arr = np.array(arr_ip, dtype=dtyp)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_attrs = {\n",
    "    \"CellID\": np.array(adata.obs.index),\n",
    "    \"nUMI\": np.array(adata.obs['n_counts'].values),\n",
    "    \"nGene\": np.array(adata.obs['n_genes'].values),\n",
    "    \"Louvain_clusters_Scanpy\": np.array( adata.obs[\"Louvain_clusters_Scanpy\"].values ),\n",
    "    \"group\": np.array(adata.obs['group'].values),\n",
    "    \"time\": np.array(adata.obs['time'].values),\n",
    "    \"sample\": np.array(adata.obs['sample'].values),\n",
    "    \"Percent_mito\": np.array(adata.obs['percent_mito'].values),\n",
    "    \"Embedding\": dfToNamedMatrix(tsneDF),\n",
    "    \"Embeddings_X\": dfToNamedMatrix(Embeddings_X),\n",
    "    \"Embeddings_Y\": dfToNamedMatrix(Embeddings_Y),\n",
    "    \"RegulonsAUC\": dfToNamedMatrix(auc_mtx)\n",
    "}\n",
    "\n",
    "row_attrs = {\n",
    "    \"Gene\": lf.ra.Gene,\n",
    "    \"Regulons\": regulons,\n",
    "}\n",
    "\n",
    "attrs = {\n",
    "    \"title\": \"sampleTitle\",\n",
    "    \"MetaData\": json.dumps(metaJson),\n",
    "    \"Genome\": 'hg38',\n",
    "    \"SCopeTreeL1\": \"\",\n",
    "    \"SCopeTreeL2\": \"\",\n",
    "    \"SCopeTreeL3\": \"\"\n",
    "}\n",
    "\n",
    "# compress the metadata field:\n",
    "attrs['MetaData'] = base64.b64encode(zlib.compress(json.dumps(metaJson).encode('ascii'))).decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp.create(\n",
    "    filename = f_final_loom ,\n",
    "    layers=lf[:,:],\n",
    "    row_attrs=row_attrs, \n",
    "    col_attrs=col_attrs, \n",
    "    file_attrs=attrs\n",
    ")\n",
    "lf.close() # close original pyscenic loom file"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
